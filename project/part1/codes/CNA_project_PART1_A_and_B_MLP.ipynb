{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c34b79-3d2f-4c0b-d3b9-26c93301b929",
        "id": "DHz_mauYYLUS"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816db5eb-0ebd-44ec-bc26-3eca98f95bfd",
        "id": "jcmzn0IAYLUU"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80822353-c223-4b6a-975a-143bd86e17a3",
        "id": "GuU5ZiX3SQ6v"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae8d06b-4f1d-4328-b129-bd5b6f6b3dd3",
        "id": "F3jmovUGYLUX"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "4ynbTYiVoXaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load citeseer**"
      ],
      "metadata": {
        "id": "wEvJbzGIR3Nz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBWVILh8YLUZ",
        "outputId": "2c018c35-b7f7-4f9d-c67e-bd77b2b9cfa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "\n",
        "\n",
        "citeseer_dataset = Planetoid(root='', name='CiteSeer')\n",
        "\n",
        "citeseer = citeseer_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load CoraFull**"
      ],
      "metadata": {
        "id": "jlV8WuThSBVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import CoraFull\n",
        "\n",
        "\n",
        "root = './CoraFull'\n",
        "\n",
        "\n",
        "CoraFull_dataset = CoraFull(root)\n",
        "\n",
        "CoraFull_dataset.download()\n",
        "CoraFull_dataset.process()\n",
        "\n",
        "CoraFull =  CoraFull_dataset[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppnuLvEY_CVp",
        "outputId": "83f8ce83-ca73-4616-bfda-3351ea17e2b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/cora.npz\n",
            "Processing...\n",
            "Done!\n",
            "Using existing file cora.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Print number of nodes, clases, edges, node features on CoraFull**"
      ],
      "metadata": {
        "id": "k9Oc-0XUYqLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "\n",
        "\n",
        "# Print statistics for the Cora Full dataset\n",
        "print(\"Cora Full Dataset Statistics:\")\n",
        "print(\"Number of Nodes: \",CoraFull.num_nodes)\n",
        "print(\"Number of Edges: \", CoraFull.num_edges)\n",
        "print(\"Number of Classes: \", CoraFull_dataset.num_classes)\n",
        "print(\"Number of Node Features: \", CoraFull.num_node_features)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC3zgqe2u_3Z",
        "outputId": "5130b472-4855-4499-9d34-08277fb18803"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cora Full Dataset Statistics:\n",
            "Number of Nodes:  19793\n",
            "Number of Edges:  126842\n",
            "Number of Classes:  70\n",
            "Number of Node Features:  8710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Print number of nodes, clases, edges, node features on CiteSeer**"
      ],
      "metadata": {
        "id": "nVZnUAXaZEXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print statistics for the CiteSeer dataset\n",
        "print(\"\\nCiteSeer Dataset Statistics:\")\n",
        "print(\"Number of Nodes: \", citeseer.num_nodes)\n",
        "print(\"Number of Edges: \", citeseer.num_edges)\n",
        "print(\"Number of Classes: \", citeseer_dataset.num_classes)\n",
        "print(\"Number of Node Features: \", citeseer.num_node_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3A2-fHVY-1a",
        "outputId": "0fa55bda-fa70-439b-a70c-c83d771c3d08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CiteSeer Dataset Statistics:\n",
            "Number of Nodes:  3327\n",
            "Number of Edges:  9104\n",
            "Number of Classes:  6\n",
            "Number of Node Features:  3703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split dataset**"
      ],
      "metadata": {
        "id": "pjSDZ7jIYLUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **split cora full**"
      ],
      "metadata": {
        "id": "5spl5OsX_blo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.transforms import RandomNodeSplit\n",
        "\n",
        "transform = RandomNodeSplit(num_train_per_class=int(CoraFull.num_nodes * 0.7), num_val=int(CoraFull.num_nodes * 0.1), num_test=int(CoraFull.num_nodes * 0.2))\n",
        "CoraFull = transform(CoraFull)"
      ],
      "metadata": {
        "id": "UotCFHaMYLUb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **split citeseer**"
      ],
      "metadata": {
        "id": "CWzjNh6n_ZzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = RandomNodeSplit(num_train_per_class=int(citeseer.num_nodes * 0.7), num_val=int(citeseer.num_nodes * 0.1), num_test=int(citeseer.num_nodes * 0.2))\n",
        "citeseer = transform(citeseer)"
      ],
      "metadata": {
        "id": "iYth3MOeYLUc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **important functions**"
      ],
      "metadata": {
        "id": "qMtwDUTKC-WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    data = data.to(device)\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def validate(model, criterion, data):\n",
        "    model.eval()\n",
        "    data = data.to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "    return val_loss.item()\n",
        "\n",
        "def test(model, criterion, data):\n",
        "    model.eval()\n",
        "    data = data.to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        _, pred = torch.max(out, dim=1)\n",
        "        correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "        acc = correct / data.test_mask.sum().item()\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "TXzM1GOJC-WL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b)implement multi layer perceptron**"
      ],
      "metadata": {
        "id": "PSMHHLr9-6UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim"
      ],
      "metadata": {
        "id": "AcerXqbf-5IP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        for dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_dim = dim\n",
        "\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x =data.x\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "LTrtlZ3M_Bw3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **train and evaluation on cora full dataset**"
      ],
      "metadata": {
        "id": "xevQodjNdEYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "#archs\n",
        "architectures = [\n",
        "\n",
        "    {'hidden_dims': [128, 64, 32 ,16], 'dropout': 0.5},\n",
        "    {'hidden_dims': [128, 64 ,32], 'dropout': 0.5},\n",
        "    {'hidden_dims': [128 ,64], 'dropout': 0.5},\n",
        "    {'hidden_dims': [128], 'dropout': 0.5},\n",
        "\n",
        "]\n",
        "\n",
        "best_architecture = None\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "\n",
        "for arch in architectures:\n",
        "\n",
        "    model = MultiLayerPerceptron(input_dim=CoraFull.num_node_features, hidden_dims=arch['hidden_dims'], output_dim=CoraFull_dataset.num_classes).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Early stopping parameters\n",
        "    patience = 5\n",
        "    min_delta = 0.001\n",
        "    patience_counter = 0\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # Train the model\n",
        "\n",
        "    for epoch in range(200):\n",
        "\n",
        "        loss = train(model, optimizer, criterion, CoraFull)\n",
        "        val_loss = validate(model, criterion, CoraFull)\n",
        "\n",
        "        # Check for improvement in validation loss\n",
        "        if val_loss < best_loss - min_delta:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch} \\n')\n",
        "                break\n",
        "\n",
        "\n",
        "        print(f'Architecture: {arch}, Epoch: {epoch}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f} ')\n",
        "\n",
        "    # Evaluate the model\n",
        "    validation_loss = validate(model= model , criterion= criterion , data = CoraFull)\n",
        "    print('Architecture: {}, Validation Loss: {:.4f}'.format(arch, validation_loss))\n",
        "\n",
        "    # Check if this architecture is the best so far\n",
        "    if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        best_architecture = arch\n",
        "\n",
        "print('Best Architecture: {}'.format(best_architecture))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmlp-supNgvT",
        "outputId": "82b94199-a5cf-4ff3-952d-ed21c305a77f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 0, Loss: 4.2702, Validation Loss: 4.2483 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 1, Loss: 4.2488, Validation Loss: 4.2066 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 2, Loss: 4.2004, Validation Loss: 4.1345 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 3, Loss: 4.1121, Validation Loss: 4.0677 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 4, Loss: 4.0163, Validation Loss: 3.9701 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 5, Loss: 3.8997, Validation Loss: 3.8652 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 6, Loss: 3.7656, Validation Loss: 3.7515 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 7, Loss: 3.6350, Validation Loss: 3.6662 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 8, Loss: 3.5010, Validation Loss: 3.6088 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 9, Loss: 3.3797, Validation Loss: 3.5307 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 10, Loss: 3.2533, Validation Loss: 3.4629 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 11, Loss: 3.1511, Validation Loss: 3.3763 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 12, Loss: 2.9888, Validation Loss: 3.3505 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 13, Loss: 2.8770, Validation Loss: 3.3561 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 14, Loss: 2.7826, Validation Loss: 3.2427 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 15, Loss: 2.6332, Validation Loss: 3.2928 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 16, Loss: 2.5762, Validation Loss: 3.1784 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 17, Loss: 2.3905, Validation Loss: 3.2124 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 18, Loss: 2.3029, Validation Loss: 3.2678 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 19, Loss: 2.1934, Validation Loss: 3.2738 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 20, Loss: 2.0634, Validation Loss: 3.2850 \n",
            "Early stopping at epoch 21 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Validation Loss: 3.2672\n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 0, Loss: 4.2339, Validation Loss: 4.1943 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 1, Loss: 4.1899, Validation Loss: 4.0961 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 2, Loss: 4.0847, Validation Loss: 3.9896 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 3, Loss: 3.9558, Validation Loss: 3.8635 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 4, Loss: 3.7946, Validation Loss: 3.7099 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 5, Loss: 3.6018, Validation Loss: 3.5638 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 6, Loss: 3.3993, Validation Loss: 3.3932 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 7, Loss: 3.1797, Validation Loss: 3.2531 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 8, Loss: 2.9586, Validation Loss: 3.1033 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 9, Loss: 2.7302, Validation Loss: 2.9675 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 10, Loss: 2.4933, Validation Loss: 2.8183 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 11, Loss: 2.2737, Validation Loss: 2.7700 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 12, Loss: 2.0738, Validation Loss: 2.6486 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 13, Loss: 1.8813, Validation Loss: 2.5670 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 14, Loss: 1.6622, Validation Loss: 2.5814 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 15, Loss: 1.5073, Validation Loss: 2.4918 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 16, Loss: 1.3304, Validation Loss: 2.5139 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 17, Loss: 1.1835, Validation Loss: 2.5031 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 18, Loss: 1.0328, Validation Loss: 2.5182 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 19, Loss: 0.9156, Validation Loss: 2.5217 \n",
            "Early stopping at epoch 20 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Validation Loss: 2.5672\n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 0, Loss: 4.2473, Validation Loss: 4.1377 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 1, Loss: 4.1219, Validation Loss: 3.9583 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 2, Loss: 3.8982, Validation Loss: 3.8435 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 3, Loss: 3.7286, Validation Loss: 3.6324 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 4, Loss: 3.4911, Validation Loss: 3.4188 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 5, Loss: 3.2399, Validation Loss: 3.2231 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 6, Loss: 2.9874, Validation Loss: 3.0018 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 7, Loss: 2.6924, Validation Loss: 2.8138 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 8, Loss: 2.4196, Validation Loss: 2.6025 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 9, Loss: 2.1264, Validation Loss: 2.4352 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 10, Loss: 1.8657, Validation Loss: 2.2924 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 11, Loss: 1.6139, Validation Loss: 2.1776 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 12, Loss: 1.3925, Validation Loss: 2.0525 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 13, Loss: 1.1768, Validation Loss: 1.9797 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 14, Loss: 1.0011, Validation Loss: 1.9388 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 15, Loss: 0.8461, Validation Loss: 1.9167 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 16, Loss: 0.7087, Validation Loss: 1.9084 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 17, Loss: 0.5942, Validation Loss: 1.8982 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 18, Loss: 0.4907, Validation Loss: 1.9230 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 19, Loss: 0.4066, Validation Loss: 1.9851 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 20, Loss: 0.3394, Validation Loss: 2.0135 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 21, Loss: 0.2758, Validation Loss: 2.0481 \n",
            "Early stopping at epoch 22 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Validation Loss: 2.1069\n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 0, Loss: 4.2529, Validation Loss: 4.0039 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 1, Loss: 3.9490, Validation Loss: 3.7017 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 2, Loss: 3.5667, Validation Loss: 3.4559 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 3, Loss: 3.2324, Validation Loss: 3.1387 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 4, Loss: 2.8400, Validation Loss: 2.8248 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 5, Loss: 2.4568, Validation Loss: 2.5564 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 6, Loss: 2.1153, Validation Loss: 2.3143 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 7, Loss: 1.7948, Validation Loss: 2.0989 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 8, Loss: 1.5009, Validation Loss: 1.9188 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 9, Loss: 1.2473, Validation Loss: 1.7735 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 10, Loss: 1.0356, Validation Loss: 1.6574 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 11, Loss: 0.8584, Validation Loss: 1.5687 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 12, Loss: 0.7098, Validation Loss: 1.5079 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 13, Loss: 0.5884, Validation Loss: 1.4691 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 14, Loss: 0.4893, Validation Loss: 1.4471 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 15, Loss: 0.4069, Validation Loss: 1.4340 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 16, Loss: 0.3368, Validation Loss: 1.4290 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 17, Loss: 0.2784, Validation Loss: 1.4344 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 18, Loss: 0.2316, Validation Loss: 1.4488 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 19, Loss: 0.1947, Validation Loss: 1.4680 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 20, Loss: 0.1652, Validation Loss: 1.4899 \n",
            "Early stopping at epoch 21 \n",
            "\n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Validation Loss: 1.5178\n",
            "Best Architecture: {'hidden_dims': [128], 'dropout': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "# Train the best model\n",
        "model = MultiLayerPerceptron(input_dim=CoraFull.num_node_features, hidden_dims=best_architecture['hidden_dims'], output_dim=CoraFull_dataset.num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 5\n",
        "min_delta = 0.001\n",
        "patience_counter = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(200):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(CoraFull).to(device)\n",
        "\n",
        "        loss = criterion(out[CoraFull.train_mask], CoraFull.y[CoraFull.train_mask])\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        val_loss = criterion(out[CoraFull.val_mask], CoraFull.y[CoraFull.val_mask])\n",
        "\n",
        "        # Check for improvement in validation loss\n",
        "        if val_loss < best_loss - min_delta:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch}')\n",
        "                break\n",
        "        print('Epoch: {:03d}, Loss: {:.4f}'.format(epoch, loss))\n",
        "\n",
        "# Evaluate the best model\n",
        "\n",
        "test_accuracy = test(model= model , criterion= criterion , data = CoraFull)\n",
        "print('Best Architecture: {}, Test Accuracy: {:.4f}'.format(best_architecture, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VRSurhyVVkr",
        "outputId": "431bc503-6638-4d12-8405-4cfee527f029"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 4.2478\n",
            "Epoch: 001, Loss: 3.9125\n",
            "Epoch: 002, Loss: 3.5630\n",
            "Epoch: 003, Loss: 3.2016\n",
            "Epoch: 004, Loss: 2.7984\n",
            "Epoch: 005, Loss: 2.4078\n",
            "Epoch: 006, Loss: 2.0475\n",
            "Epoch: 007, Loss: 1.7208\n",
            "Epoch: 008, Loss: 1.4273\n",
            "Epoch: 009, Loss: 1.1760\n",
            "Epoch: 010, Loss: 0.9686\n",
            "Epoch: 011, Loss: 0.7971\n",
            "Epoch: 012, Loss: 0.6585\n",
            "Epoch: 013, Loss: 0.5447\n",
            "Epoch: 014, Loss: 0.4491\n",
            "Epoch: 015, Loss: 0.3695\n",
            "Epoch: 016, Loss: 0.3047\n",
            "Epoch: 017, Loss: 0.2524\n",
            "Epoch: 018, Loss: 0.2100\n",
            "Epoch: 019, Loss: 0.1761\n",
            "Epoch: 020, Loss: 0.1494\n",
            "Early stopping at epoch 21\n",
            "Best Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Test Accuracy: 0.6309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **train and evaluation on CiteSeer dataset**"
      ],
      "metadata": {
        "id": "8lnAINT6dAJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "#archs\n",
        "architectures = [\n",
        "\n",
        "    {'hidden_dims': [128, 64, 32 ,16], 'dropout': 0.5},\n",
        "    {'hidden_dims': [128, 64 ,32], 'dropout': 0.5},\n",
        "    {'hidden_dims': [128 ,64], 'dropout': 0.5},\n",
        "    {'hidden_dims': [128], 'dropout': 0.5},\n",
        "\n",
        "]\n",
        "best_architecture = None\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "\n",
        "for arch in architectures:\n",
        "\n",
        "    model = MultiLayerPerceptron(input_dim=citeseer.num_node_features, hidden_dims=arch['hidden_dims'], output_dim=citeseer_dataset.num_classes).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    patience = 5\n",
        "    min_delta = 0.001\n",
        "    patience_counter = 0\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(200):\n",
        "\n",
        "        loss = train(model, optimizer, criterion, citeseer)\n",
        "        val_loss = validate(model, criterion, citeseer)\n",
        "\n",
        "        # Check for improvement in validation loss\n",
        "        if val_loss < best_loss - min_delta:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch} \\n')\n",
        "                break\n",
        "\n",
        "\n",
        "        print(f'Architecture: {arch}, Epoch: {epoch}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f} ')\n",
        "\n",
        "    # Evaluate the model\n",
        "    validation_loss = validate(model= model , criterion= criterion , data = citeseer)\n",
        "    print('Architecture: {}, Validation Loss: {:.4f} \\n'.format(arch, validation_loss))\n",
        "\n",
        "    # Check if this architecture is the best so far\n",
        "    if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        best_architecture = arch\n",
        "\n",
        "print('Best Architecture: {}'.format(best_architecture))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e055ae-8f53-45a0-a0c0-f67676e967ed",
        "id": "nuGDYCKVd5oJ"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 0, Loss: 1.7976, Validation Loss: 1.7706 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 1, Loss: 1.7733, Validation Loss: 1.7268 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 2, Loss: 1.7128, Validation Loss: 1.6575 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 3, Loss: 1.6056, Validation Loss: 1.5788 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 4, Loss: 1.4670, Validation Loss: 1.4505 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 5, Loss: 1.2915, Validation Loss: 1.3437 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 6, Loss: 1.1335, Validation Loss: 1.3128 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 7, Loss: 1.0078, Validation Loss: 1.3534 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 8, Loss: 0.8765, Validation Loss: 1.3214 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 9, Loss: 0.7309, Validation Loss: 1.3434 \n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Epoch: 10, Loss: 0.6064, Validation Loss: 1.3524 \n",
            "Early stopping at epoch 11 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64, 32, 16], 'dropout': 0.5}, Validation Loss: 1.4795 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 0, Loss: 1.7948, Validation Loss: 1.7847 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 1, Loss: 1.7770, Validation Loss: 1.7430 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 2, Loss: 1.7229, Validation Loss: 1.6552 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 3, Loss: 1.6067, Validation Loss: 1.5248 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 4, Loss: 1.4198, Validation Loss: 1.3930 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 5, Loss: 1.1921, Validation Loss: 1.2395 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 6, Loss: 0.9547, Validation Loss: 1.1121 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 7, Loss: 0.7370, Validation Loss: 1.0206 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 8, Loss: 0.5339, Validation Loss: 0.9621 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 9, Loss: 0.3676, Validation Loss: 1.0684 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 10, Loss: 0.2568, Validation Loss: 1.1963 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 11, Loss: 0.1569, Validation Loss: 1.3771 \n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Epoch: 12, Loss: 0.0989, Validation Loss: 1.5952 \n",
            "Early stopping at epoch 13 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64, 32], 'dropout': 0.5}, Validation Loss: 1.8169 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 0, Loss: 1.7939, Validation Loss: 1.7299 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 1, Loss: 1.7013, Validation Loss: 1.5672 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 2, Loss: 1.4868, Validation Loss: 1.3498 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 3, Loss: 1.1887, Validation Loss: 1.1266 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 4, Loss: 0.8788, Validation Loss: 0.9626 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 5, Loss: 0.6184, Validation Loss: 0.8730 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 6, Loss: 0.4232, Validation Loss: 0.8337 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 7, Loss: 0.2724, Validation Loss: 0.8819 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 8, Loss: 0.1757, Validation Loss: 0.9840 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 9, Loss: 0.1098, Validation Loss: 1.1083 \n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Epoch: 10, Loss: 0.0623, Validation Loss: 1.3011 \n",
            "Early stopping at epoch 11 \n",
            "\n",
            "Architecture: {'hidden_dims': [128, 64], 'dropout': 0.5}, Validation Loss: 1.4943 \n",
            "\n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 0, Loss: 1.7947, Validation Loss: 1.6127 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 1, Loss: 1.5379, Validation Loss: 1.3925 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 2, Loss: 1.2111, Validation Loss: 1.1898 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 3, Loss: 0.9074, Validation Loss: 0.9930 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 4, Loss: 0.6453, Validation Loss: 0.8633 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 5, Loss: 0.4609, Validation Loss: 0.7976 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 6, Loss: 0.3285, Validation Loss: 0.7882 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 7, Loss: 0.2364, Validation Loss: 0.8189 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 8, Loss: 0.1734, Validation Loss: 0.8482 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 9, Loss: 0.1167, Validation Loss: 0.8871 \n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Epoch: 10, Loss: 0.0760, Validation Loss: 0.9428 \n",
            "Early stopping at epoch 11 \n",
            "\n",
            "Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Validation Loss: 1.0058 \n",
            "\n",
            "Best Architecture: {'hidden_dims': [128], 'dropout': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "# Train the best model\n",
        "model = MultiLayerPerceptron(input_dim=citeseer.num_node_features, hidden_dims=best_architecture['hidden_dims'], output_dim=citeseer_dataset.num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01) # Reset the optimizer state\n",
        "\n",
        "# Early stopping parameters\n",
        "\n",
        "patience = 5\n",
        "min_delta = 0.001\n",
        "patience_counter = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(200):\n",
        "\n",
        "        loss = train(model, optimizer, criterion, citeseer)\n",
        "        val_loss = validate(model, criterion, citeseer)\n",
        "\n",
        "        # Check for improvement in validation loss\n",
        "        if val_loss < best_loss - min_delta:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch}')\n",
        "                break\n",
        "        print('Epoch: {:03d}, Loss: {:.4f}'.format(epoch, loss))\n",
        "\n",
        "# Evaluate the best model\n",
        "test_accuracy = test(model= model , criterion= criterion , data = citeseer)\n",
        "print('Best Architecture: {}, Test Accuracy: {:.4f}'.format(best_architecture, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7baf435-9bb6-4eb3-ea1a-1efc73113f76",
        "id": "K1zr9vw-d5oK"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 1.7952\n",
            "Epoch: 001, Loss: 1.5321\n",
            "Epoch: 002, Loss: 1.2054\n",
            "Epoch: 003, Loss: 0.9048\n",
            "Epoch: 004, Loss: 0.6520\n",
            "Epoch: 005, Loss: 0.4633\n",
            "Epoch: 006, Loss: 0.3293\n",
            "Epoch: 007, Loss: 0.2360\n",
            "Epoch: 008, Loss: 0.1680\n",
            "Epoch: 009, Loss: 0.1109\n",
            "Epoch: 010, Loss: 0.0724\n",
            "Early stopping at epoch 11\n",
            "Best Architecture: {'hidden_dims': [128], 'dropout': 0.5}, Test Accuracy: 0.7158\n"
          ]
        }
      ]
    }
  ]
}